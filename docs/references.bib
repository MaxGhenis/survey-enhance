@misc{dwp_110,
	author = {McKay, Stephen},
	publisher = {Department for Work and Pensions},
	title = {Evaluating approaches to {Family} {Resources} {Survey} data linking},
	url = {https://www.gov.uk/government/publications/family-resources-survey-data-linking-wp110},
	bdsk-url-1 = {https://www.gov.uk/government/publications/family-resources-survey-data-linking-wp110}}


@article{frs_capital_income,
	abstract = {This paper proposes a methodological framework to better incorporate non-labour income into existing top adjusted indicators of economic inequality. Surveys are known to miss the rich, receiving disproportionate amounts of capital income. There has been a surge in top harmonisation methodologies, which complement survey-based estimates of inequality with information from the rich reported in tax administrative sources. These harmonisation methods are found to have a significant upward effect on inequality indicators. This analysis uses the Family Resources Survey (household survey) and the Survey of Personal Incomes (tax data) to explore the extent to which existing UK harmonisation methodology corrects for capital income. First, this analysis finds that the FRS has experienced a significant decline in capital income measurement over the past 20 years (1997--2016), taking reported levels of capital income in the SPI as benchmark. Second, the top harmonisation methodology is found to only partially correct for this decline. Third, in response, the paper proposes a multi-step capital income correction to allocate the remaining capital income missing from top adjusted inequality indicators. The adjustment accounts for both under-coverage and under-estimation error of capital income across the income distribution. Poor measurement of capital incomes in household surveys has long been acknowledged but attempts to correct for this have remained few. This paper highlights the need for decomposable top adjusted indicators of inequality to give a better picture of the role of capital incomes in driving inequality. Surveys are traditionally used to produce inequality indicators used by governments, statistical offices and policy makers. The policy implication is that income missing from indicators structurally falls out of inequality debates, which has arguably been the case for capital incomes.},
	author = {Ooms, Tahnee Christelle},
	date = {2021/10/01},
	date-added = {2022-10-16 15:58:14 +0100},
	date-modified = {2022-10-16 15:58:14 +0100},
	doi = {10.1007/s11205-021-02644-4},
	id = {Ooms2021},
	isbn = {1573-0921},
	journal = {Social Indicators Research},
	number = {3},
	pages = {929--953},
	title = {Correcting the Underestimation of Capital Incomes in Inequality Indicators: with an Application to the UK, 1997--2016},
	url = {https://doi.org/10.1007/s11205-021-02644-4},
	volume = {157},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1007/s11205-021-02644-4}}


@article{ifs_survey_under_coverage,
	abstract = {Abstract Survey under-coverage of top incomes leads to bias in survey-based estimates of overall income inequality. Using income tax record data in combination with survey data is a potential approach to address the problem; we consider here the UK's pioneering `SPI adjustment' method that implements this idea. Since 1992, the principal income distribution series (reported annually in Households Below Average Income) has been based on household survey data in which the incomes of a small number of `very rich' individuals are adjusted using information from `very rich' individuals in personal income tax return data. We explain what the procedure involves, reveal the extent to which it addresses survey under-coverage of top incomes and show how it affects estimates of overall income inequality. More generally, we assess whether the SPI adjustment is fit for purpose and consider whether variants of it could be employed by other countries.},
	author = {Burkhauser, Richard V. and H{\'e}rault, Nicolas and Jenkins, Stephen P. and Wilkins, Roger},
	doi = {https://doi.org/10.1111/1475-5890.12158},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/1475-5890.12158},
	journal = {Fiscal Studies},
	keywords = {inequality, income inequality, survey under-coverage, SPI adjustment, top incomes, tax return data, survey data, D31, C81},
	number = {2},
	pages = {213-240},
	title = {Survey Under-Coverage of Top Incomes and Estimation of Inequality: What is the Role of the UK's SPI Adjustment?},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1475-5890.12158},
	volume = {39},
	year = {2018},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1475-5890.12158},
	bdsk-url-2 = {https://doi.org/10.1111/1475-5890.12158}}


@article{brewer_low_income_coverage,
	abstract = {We document that households in the UK with extremely low measured income tend to spend much more than those with merely moderately low income. This phenomenon is evident throughout three decades worth of microdata and across different employment states, levels of education and marital statuses. Of the likely explanations, we provide several arguments that discount over-reporting of expenditure and argue that under-reporting of income plays the major role. In particular, by using a dynamic model of consumption and saving, and paying special attention to poverty dynamics, we show that consumption smoothing cannot explain all the apparent dissaving.},
	author = {Brewer, Mike and Etheridge, Ben and O'Dea, Cormac},
	doi = {https://doi.org/10.1111/ecoj.12334},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/ecoj.12334},
	journal = {The Economic Journal},
	number = {605},
	pages = {F24-F49},
	title = {Why are Households that Report the Lowest Incomes So Well-off?},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ecoj.12334},
	volume = {127},
	year = {2017},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ecoj.12334},
	bdsk-url-2 = {https://doi.org/10.1111/ecoj.12334}}

@article{ons_spi_version_2,
	author={Richard Tonkin and Dominic Webber and Ozer Beha and Martin Shine and Callum Clark},
	journal={ONS},
	url={https://www.ons.gov.uk/economy/nationalaccounts/uksectoraccounts/compendium/ economicreview/february2020/topincomeadjustmentineffectsoftaxesandbenefitsdatamethodology},
	title={Top income adjustment in effects of taxes and benefits data: methodology},
	year={2020},
	}

@article{hbai,
	author={DWP},
	journal={GOV.UK},
	year={1992},
	url={https://www.gov.uk/government/collections/households-below-average-income-hbai--2},
	title={Households Below Average Income (HBAI) statistics},
}


@article{ukmod,
	abstract = {In this paper we introduce UKMOD, a new tax-benefit model for England, Wales, Scotland, Northern Ireland and the whole of the UK. The model originates and replaces as a stand-alone model the UK component of EUROMOD, the tax-benefit model for the European Union member states, which from 2021 is not updated anymore. We describe the main departures from EUROMOD, discuss some key assumptions including data issues, and provide information on the nowcasting and macro-validation procedure applied.},
	article_type = {journal},
	author = {Richiardi, Matteo and Collado, Diego and Popova, Daria},
	citation = {IJM 2021;14(1):92-101},
	doi = {10.34196/ijm.00231},
	issn = {1747-5864},
	journal = {IJM},
	keywords = {UK, microsimulation, EUROMOD, UKMOD},
	month = {apr},
	number = 1,
	pages = {92-101},
	pub_date = {2021-04-30},
	publisher = {International Journal of Microsimulation},
	title = {UKMOD -- A new tax-benefit model for the four nations of the UK},
	url = {https://doi.org/10.34196/ijm.00231},
	volume = 14,
	year = 2021,
	bdsk-url-1 = {https://doi.org/10.34196/ijm.00231}}

@article{image_classification_survey,
author = {Lu, Dengsheng},
year = {2007},
month = {03},
pages = {823 - 870},
title = {A Survey of Image Classification Methods and Techniques for Improving Classification Performance},
volume = {28},
journal = {International Journal of Remote Sensing},
doi = {10.1080/01431160600746456}
}

@ARTICLE{gradient_descent,
  author={Baldi, P.},
  journal={IEEE Transactions on Neural Networks}, 
  title={Gradient descent learning algorithm overview: a general dynamical systems perspective}, 
  year={1995},
  volume={6},
  number={1},
  pages={182-195},
  doi={10.1109/72.363438}}


@InProceedings{sgd,
  title = 	 {An Empirical Study of Stochastic Gradient Descent with Structured Covariance Noise},
  author =       {Wen, Yeming and Luk, Kevin and Gazeau, Maxime and Zhang, Guodong and Chan, Harris and Ba, Jimmy},
  booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages = 	 {3621--3631},
  year = 	 {2020},
  editor = 	 {Chiappa, Silvia and Calandra, Roberto},
  volume = 	 {108},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {26--28 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v108/wen20a/wen20a.pdf},
  url = 	 {https://proceedings.mlr.press/v108/wen20a.html},
  abstract = 	 {The choice of batch-size in a stochastic optimization algorithm plays a substantial role for both optimization and generalization. Increasing the batch-size used typically improves optimization but degrades generalization. To address the problem of improving generalization while maintaining optimal convergence in large-batch training, we propose to add covariance noise to the gradients. We demonstrate that the learning performance of our method is more accurately captured by the structure of the covariance matrix of the noise rather than by the variance of gradients. Moreover, over the convex-quadratic, we prove in theory that it can be characterized by the Frobenius norm of the noise matrix. Our empirical studies with standard deep learning model-architectures and datasets shows that our method not only improves generalization performance in large-batch training, but furthermore, does so in a way where the optimization performance remains desirable and the training duration is not elongated.}
}

@INPROCEEDINGS{mini_batch,
  author={Khirirat, Sarit and Feyzmahdavian, Hamid Reza and Johansson, Mikael},
  booktitle={2017 IEEE 56th Annual Conference on Decision and Control (CDC)}, 
  title={Mini-batch gradient descent: Faster convergence under data sparsity}, 
  year={2017},
  volume={},
  number={},
  pages={2880-2887},
  doi={10.1109/CDC.2017.8264077}}

@inproceedings{adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{adagrad,
  author  = {John Duchi and Elad Hazan and Yoram Singer},
  title   = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
  journal = {Journal of Machine Learning Research},
  year    = {2011},
  volume  = {12},
  number  = {61},
  pages   = {2121--2159},
  url     = {http://jmlr.org/papers/v12/duchi11a.html}
}


@article{random_forests,
	abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148--156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
	author = {Breiman, Leo},
	date = {2001/10/01},
	date-added = {2022-10-27 10:40:45 +0100},
	date-modified = {2022-10-27 10:40:45 +0100},
	doi = {10.1023/A:1010933404324},
	id = {Breiman2001},
	isbn = {1573-0565},
	journal = {Machine Learning},
	number = {1},
	pages = {5--32},
	title = {Random Forests},
	url = {https://doi.org/10.1023/A:1010933404324},
	volume = {45},
	year = {2001},
	bdsk-url-1 = {https://doi.org/10.1023/A:1010933404324}}

@article{anns,
author = {Schöllhorn, Wolfgang and Jäger, Jörg},
year = {2006},
month = {01},
pages = {20-58},
title = {A Survey on Various Applications of Artificial Neural Networks in Selected Fields of Healthcare},
isbn = {9781591408505},
journal = {Neural Networks in Healthcare: Potential and Challenges},
doi = {10.4018/978-1-59140-848-2.ch002}
}


@inproceedings{transformers,
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	publisher = {Curran Associates, Inc.},
	title = {Attention is All you Need},
	url = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
	volume = {30},
	year = {2017},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}}

@article{ecb,
	author = {Jarmulska, Barbara},
	year={2020},
	month={05},
	journal = {European Central Bank Working Papers},
	title = {Random forest versus logit models: which offers better early warning
of fiscal stress?},
	url = {https://www.ecb.europa.eu/pub/pdf/scpwps/ecb.wp2408~aa6b05aed7.en.pdf?9551c7c6e8e8fdbd35e5512b5afcf097},
}

@article{linear_programming,
author = {Schulze, Mark},
year = {2000},
month = {09},
title = {Linear Programming for Optimization}
}


@article{frs_weighting_review,
author = {Charles Lound and Peter Broad},
year = {2013},
month = {06},
journal = {Office for National Statistics},
title = {Initial review of the Family Resources Survey weighting scheme}
}


@article{tpc_microsim_docs,
author = {Tax Policy Center},
journal = {TPC},
year = {2022},
month = {09},
title = {Tax model documentation},
url = {https://www.taxpolicycenter.org/resources/brief-description-tax-model}
}

@article{taxdata_github,
author = {Policy Simulation Library},
journal = {GitHub},
title = {Tax-Data model documentation},
url = {https://github.com/pslmodels/taxdata},
year = {2020},
}


@article{cg_bunching,
	abstract = { We use a unique data set of capital gains transactions to investigate the behavior of taxpayers with respect to the preferential tax rate for long-term capital gains. Our data allow us to examine the shifting of gains across time periods but eliminate the effect of the large pool of accrued gains that mechanically enlarge previous estimates. We adapt the bunching methodology developed by Kleven and Wasseem for rate changes over incomes to the drop in the capital gains tax when an asset has been held for more than one year. We find strong evidence that taxpayers respond to the preferential rate by reducing the realizations of gains in the weeks leading up to the point when the preferential rate applies. However, the magnitude of the transitory elasticity is small relative to prior estimates: we estimate a short-run gains elasticity of −0.47. We also estimate a quasi-permanent gains elasticity of −0.79. },
	author = {Dowd, Tim and McClelland, Robert},
	doi = {10.17310/ntj.2019.2.02},
	eprint = {https://doi.org/10.17310/ntj.2019.2.02},
	journal = {National Tax Journal},
	number = {2},
	pages = {323-358},
	title = {THE BUNCHING OF CAPITAL GAINS REALIZATIONS},
	url = {https://doi.org/10.17310/ntj.2019.2.02},
	volume = {72},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.17310/ntj.2019.2.02}}
